% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/plotImportance.R
\name{plotImportance}
\alias{plotImportance}
\title{Plot function for feature importance}
\usage{
plotImportance(importance, feature, mid, individual = FALSE,
  hline = TRUE, grid.points = TRUE)
}
\arguments{
\item{importance}{[\code{featureImportance | data.frame}] \cr
Object of class \code{featureImportance} or a \code{data.frame} containing the same information as the result of \code{featureImportance} from its \code{$importance} slot.}

\item{feature}{[\code{character(1)}] \cr
The feature(s) for which the shapley importance should be computed.}

\item{bound.size}{[\code{numeric(1)}] \cr
Bound on the permutation size to compute the Shapley value (see Cohen et al. (2007)).}

\item{n.shapley.perm}{[\code{numeric(1)}] \cr
The number of permutations that should be used for the shapley value (for computational reasons the maximum allowed value is 8192).
If \code{n.shapley.perm} >= number of all unique permutatios, all unique permutations will be used.
Use \code{n.shapley.perm = NULL} to use all unique permutations (or the maximum allowed value of 8192)
Default is 120.}

\item{value.function}{[\code{function}] \cr
Function that defines the value function which is used to compute the shapley value.}
}
\description{
Allows to visualize the PI or ICI curves.
}
\references{
Casalicchio, G., Molnar, M., & Bischl, B. (2018).
Visualizing the Feature Importance for Black Box Models.
arXiv preprint arXiv:1804.06620 (2018).
}
